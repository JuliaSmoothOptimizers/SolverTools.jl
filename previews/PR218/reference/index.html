<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Reference · SolverTools.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/style.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="SolverTools.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">SolverTools.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Reference</a><ul class="internal"><li><a class="tocitem" href="#Contents"><span>Contents</span></a></li><li><a class="tocitem" href="#Index"><span>Index</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Reference</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Reference</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaSmoothOptimizers/SolverTools.jl/blob/master/docs/src/reference.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Reference"><a class="docs-heading-anchor" href="#Reference">Reference</a><a id="Reference-1"></a><a class="docs-heading-anchor-permalink" href="#Reference" title="Permalink"></a></h1><p>​</p><h2 id="Contents"><a class="docs-heading-anchor" href="#Contents">Contents</a><a id="Contents-1"></a><a class="docs-heading-anchor-permalink" href="#Contents" title="Permalink"></a></h2><p>​</p><ul><li><a href="#Reference">Reference</a></li><ul><li><a href="#Contents">Contents</a></li><li><a href="#Index">Index</a></li></ul></ul><p>​</p><h2 id="Index"><a class="docs-heading-anchor" href="#Index">Index</a><a id="Index-1"></a><a class="docs-heading-anchor-permalink" href="#Index" title="Permalink"></a></h2><p>​</p><ul><li><a href="#SolverTools.ARTrustRegion"><code>SolverTools.ARTrustRegion</code></a></li><li><a href="#SolverTools.AbstractTrustRegion"><code>SolverTools.AbstractTrustRegion</code></a></li><li><a href="#SolverTools.LineModel"><code>SolverTools.LineModel</code></a></li><li><a href="#SolverTools.TRONTrustRegion"><code>SolverTools.TRONTrustRegion</code></a></li><li><a href="#SolverTools.TrustRegion"><code>SolverTools.TrustRegion</code></a></li><li><a href="#SolverTools.TrustRegionException"><code>SolverTools.TrustRegionException</code></a></li><li><a href="#LinearOperators.reset!-Tuple{SolverTools.AbstractTrustRegion}"><code>LinearOperators.reset!</code></a></li><li><a href="#NLPModels.grad-Tuple{LineModel, AbstractFloat}"><code>NLPModels.grad</code></a></li><li><a href="#NLPModels.grad!-Tuple{LineModel, AbstractFloat, AbstractVector}"><code>NLPModels.grad!</code></a></li><li><a href="#NLPModels.hess-Tuple{LineModel, AbstractFloat}"><code>NLPModels.hess</code></a></li><li><a href="#NLPModels.obj-Tuple{LineModel, AbstractFloat}"><code>NLPModels.obj</code></a></li><li><a href="#NLPModels.objgrad-Tuple{LineModel, AbstractFloat}"><code>NLPModels.objgrad</code></a></li><li><a href="#NLPModels.objgrad!-Tuple{LineModel, AbstractFloat, AbstractVector}"><code>NLPModels.objgrad!</code></a></li><li><a href="#SolverTools.acceptable-Tuple{SolverTools.AbstractTrustRegion}"><code>SolverTools.acceptable</code></a></li><li><a href="#SolverTools.active-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}, AbstractVector{T}}} where T&lt;:Real"><code>SolverTools.active</code></a></li><li><a href="#SolverTools.active!-Union{Tuple{T}, Tuple{BitVector, AbstractVector{T}, AbstractVector{T}, AbstractVector{T}}} where T&lt;:Real"><code>SolverTools.active!</code></a></li><li><a href="#SolverTools.aredpred!-Union{Tuple{V}, Tuple{T}, Tuple{SolverTools.AbstractTrustRegion{T, V}, NLPModels.AbstractNLPModel{T, V}, T, T, T, V, V, T}} where {T, V}"><code>SolverTools.aredpred!</code></a></li><li><a href="#SolverTools.aredpred_common-Union{Tuple{V}, Tuple{T}, Tuple{NLPModels.AbstractNLPModel{T, V}, T, T, T, V, V, V, T}} where {T, V}"><code>SolverTools.aredpred_common</code></a></li><li><a href="#SolverTools.armijo_condition-Union{Tuple{T}, NTuple{5, T}} where T"><code>SolverTools.armijo_condition</code></a></li><li><a href="#SolverTools.armijo_goldstein-Union{Tuple{T}, Tuple{LineModel, T, T}} where T&lt;:AbstractFloat"><code>SolverTools.armijo_goldstein</code></a></li><li><a href="#SolverTools.armijo_wolfe-Union{Tuple{T}, Tuple{LineModel, T, T, Vector{T}}} where T&lt;:AbstractFloat"><code>SolverTools.armijo_wolfe</code></a></li><li><a href="#SolverTools.breakpoints-Union{Tuple{T}, NTuple{4, AbstractVector{T}}} where T&lt;:Real"><code>SolverTools.breakpoints</code></a></li><li><a href="#SolverTools.compute_As_slope_qs!-Union{Tuple{T}, Tuple{AbstractVector{T}, Union{LinearOperators.AbstractLinearOperator, AbstractMatrix}, AbstractVector{T}, AbstractVector{T}}} where T&lt;:Real"><code>SolverTools.compute_As_slope_qs!</code></a></li><li><a href="#SolverTools.compute_Hs_slope_qs!-Union{Tuple{T}, Tuple{AbstractVector{T}, Union{LinearOperators.AbstractLinearOperator, AbstractMatrix}, AbstractVector{T}, AbstractVector{T}}} where T&lt;:Real"><code>SolverTools.compute_Hs_slope_qs!</code></a></li><li><a href="#SolverTools.compute_r-Union{Tuple{T}, Tuple{Any, T, Vararg{Any, 7}}} where T"><code>SolverTools.compute_r</code></a></li><li><a href="#SolverTools.goldstein_condition-Union{Tuple{T}, NTuple{5, T}} where T"><code>SolverTools.goldstein_condition</code></a></li><li><a href="#SolverTools.hess!-Tuple{LineModel, AbstractFloat, AbstractVector}"><code>SolverTools.hess!</code></a></li><li><a href="#SolverTools.project!-Union{Tuple{T}, NTuple{4, AbstractVector{T}}} where T&lt;:Real"><code>SolverTools.project!</code></a></li><li><a href="#SolverTools.project_step!-Union{Tuple{T}, NTuple{5, AbstractVector{T}}, Tuple{AbstractVector{T}, AbstractVector{T}, AbstractVector{T}, AbstractVector{T}, AbstractVector{T}, Real}} where T&lt;:Real"><code>SolverTools.project_step!</code></a></li><li><a href="#SolverTools.redirect!-Tuple{LineModel, AbstractVector, AbstractVector}"><code>SolverTools.redirect!</code></a></li><li><a href="#SolverTools.update!"><code>SolverTools.update!</code></a></li></ul><p>​</p><article class="docstring"><header><a class="docstring-binding" id="SolverTools.ARTrustRegion" href="#SolverTools.ARTrustRegion"><code>SolverTools.ARTrustRegion</code></a> — <span class="docstring-category">Type</span></header><section><div><p>ARTrustRegion(α₀::T;kwargs...)</p><p>Select the main parameters used in the <code>TRARC</code> algorithm with <code>α₀</code> as initial TR/ARC parameter. The keyword arguments are:</p><ul><li><code>max_α::T</code>: Maximum value for <code>α</code>. Default <code>T(1) / sqrt(eps(T))</code>.</li><li><code>acceptance_threshold::T</code>: Ratio over which the step is successful. Default <code>T(0.1)</code>.</li><li><code>increase_threshold::T</code>: Ratio over which we increase <code>α</code>. Default <code>T(0.75)</code>.</li><li><code>reduce_threshold::T</code>: Ratio under which we decrease <code>α</code>. Default <code>T(0.1)</code>.</li><li><code>increase_factor::T</code>: Factor of increase of <code>α</code>. Default <code>T(5.0)</code>.</li><li><code>decrease_factor::T</code>: Factor of decrease of <code>α</code>. Default <code>T(0.1)</code>.</li><li><code>max_unsuccinarow::Int</code>: Limit on the number of successive unsucessful iterations. Default <code>30</code>.</li></ul><p>Returns a <code>ARTrustRegion</code> structure.</p><p>This can be compared to <code>TrustRegion</code> or <code>TRONTrustRegion</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/SolverTools.jl/blob/328d30ab39f277f4784c373b13a3c5c0c230bc7f/src/trust-region/ar-trust-region.jl#L3-L19">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverTools.AbstractTrustRegion" href="#SolverTools.AbstractTrustRegion"><code>SolverTools.AbstractTrustRegion</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>AbstractTrustRegion</code></p><p>An abstract trust region type so that specific trust regions define update rules differently. Child types must have at least the following real fields:</p><ul><li><code>acceptance_threshold</code></li><li><code>initial_radius</code></li><li><code>radius</code></li><li><code>ratio</code></li></ul><p>and the following function:</p><ul><li><code>update!(tr, step_norm)</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/SolverTools.jl/blob/328d30ab39f277f4784c373b13a3c5c0c230bc7f/src/trust-region/trust-region.jl#L10-L24">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverTools.LineModel" href="#SolverTools.LineModel"><code>SolverTools.LineModel</code></a> — <span class="docstring-category">Type</span></header><section><div><p>A type to represent the restriction of a function to a direction. Given f : R → Rⁿ, x ∈ Rⁿ and a nonzero direction d ∈ Rⁿ,</p><pre><code class="language-none">ϕ = LineModel(nlp, x, d)</code></pre><p>represents the function ϕ : R → R defined by</p><pre><code class="language-none">ϕ(t) := f(x + td).</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/SolverTools.jl/blob/328d30ab39f277f4784c373b13a3c5c0c230bc7f/src/linesearch/line_model.jl#L6-L15">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverTools.TRONTrustRegion" href="#SolverTools.TRONTrustRegion"><code>SolverTools.TRONTrustRegion</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">TRONTrustRegion{T, V} &lt;: AbstractTrustRegion{T, V}</code></pre><p>Trust region used by TRON that contains the following fields:</p><ul><li><code>initial_radius::T</code>: initial radius;</li><li><code>radius::T</code>: current radius;</li><li><code>max_radius::T</code>: upper bound on the radius (default <code>1 / sqrt(eps(T))</code>);</li><li><code>acceptance_threshold::T</code>: decrease radius if ratio is below this threshold between 0 and 1 (default <code>1e-4</code>);</li><li><code>decrease_threshold::T</code>: ...between 0 and 1  (default <code>0.25</code>);</li><li><code>increase_threshold::T</code>: increase radius if ratio is beyond this threshold between 0 and 1  (default <code>0.75</code>);</li><li><code>large_decrease_factor::T</code>: decrease factor between 0 and 1  (default <code>0.25</code>);</li><li><code>small_decrease_factor::T</code>: decrease factor between 0 and 1  (default <code>0.5</code>);</li><li><code>increase_factor::T</code>: increase factor greater than one (default <code>4</code>);</li><li><code>ratio::T</code>: current ratio <code>ared / pred</code>;</li><li><code>quad_min::T</code>: ...;</li><li><code>gt::V</code>: pre-allocated memory vector to store the gradient of the objective function;</li><li><code>good_grad::Bool</code>: <code>true</code> if <code>gt</code> is the gradient of the objective function at the trial point.</li></ul><p>The following constructors are available:</p><pre><code class="language-none">TRONTrustRegion(gt,::V initial_radius::T; kwargs...)</code></pre><p>If <code>gt</code> is not known, it is possible to use the following constructors:</p><pre><code class="language-none">TRONTrustRegion(::Type{V}, n::Int, Δ₀::T; kwargs...)
TRONTrustRegion(n::Int, Δ₀::T; kwargs...)</code></pre><p>that will allocate a vector of size <code>n</code> and type <code>V</code> or <code>Vector{T}</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/SolverTools.jl/blob/328d30ab39f277f4784c373b13a3c5c0c230bc7f/src/trust-region/tron-trust-region.jl#L3-L31">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverTools.TrustRegion" href="#SolverTools.TrustRegion"><code>SolverTools.TrustRegion</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">TrustRegion{T, V} &lt;: AbstractTrustRegion{T, V}</code></pre><p>Basic trust region type that contains the following fields:</p><ul><li><code>initial_radius::T</code>: initial radius;</li><li><code>radius::T</code>: current radius;</li><li><code>max_radius::T</code>: upper bound on the radius (default <code>1 / sqrt(eps(T))</code>);</li><li><code>acceptance_threshold::T</code>: decrease radius if ratio is below this threshold between 0 and 1 (default <code>1e-4</code>);</li><li><code>increase_threshold::T</code>: increase radius if ratio is beyond this threshold between 0 and 1  (default <code>0.95</code>);</li><li><code>decrease_factor::T</code>: decrease factor less between 0 and 1 (default <code>1 / 3</code>);</li><li><code>increase_factor::T</code>: increase factor greater than one (default <code>3 / 2</code>);</li><li><code>ratio::T</code>: current ratio <code>ared / pred</code>;</li><li><code>gt::V</code>: pre-allocated memory vector to store the gradient of the objective function;</li><li><code>good_grad::Bool</code>: <code>true</code> if <code>gt</code> is the gradient of the objective function at the trial point.</li></ul><p>The following constructors are available:</p><pre><code class="language-none">TrustRegion(gt,::V initial_radius::T; kwargs...)</code></pre><p>If <code>gt</code> is not known, it is possible to use the following constructors:</p><pre><code class="language-none">TrustRegion(::Type{V}, n::Int, Δ₀::T; kwargs...)
TrustRegion(n::Int, Δ₀::T; kwargs...)</code></pre><p>that will allocate a vector of size <code>n</code> and type <code>V</code> or <code>Vector{T}</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/SolverTools.jl/blob/328d30ab39f277f4784c373b13a3c5c0c230bc7f/src/trust-region/basic-trust-region.jl#L3-L28">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverTools.TrustRegionException" href="#SolverTools.TrustRegionException"><code>SolverTools.TrustRegionException</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Exception type raised in case of error.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/SolverTools.jl/blob/328d30ab39f277f4784c373b13a3c5c0c230bc7f/src/trust-region/trust-region.jl#L5">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearOperators.reset!-Tuple{SolverTools.AbstractTrustRegion}" href="#LinearOperators.reset!-Tuple{SolverTools.AbstractTrustRegion}"><code>LinearOperators.reset!</code></a> — <span class="docstring-category">Method</span></header><section><div><p><code>reset!(tr)</code></p><p>Reset the trust-region radius to its initial value.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/SolverTools.jl/blob/328d30ab39f277f4784c373b13a3c5c0c230bc7f/src/trust-region/trust-region.jl#L157-L161">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.grad!-Tuple{LineModel, AbstractFloat, AbstractVector}" href="#NLPModels.grad!-Tuple{LineModel, AbstractFloat, AbstractVector}"><code>NLPModels.grad!</code></a> — <span class="docstring-category">Method</span></header><section><div><p><code>grad!(f, t, g)</code> evaluates the first derivative of the <code>LineModel</code></p><pre><code class="language-none">ϕ(t) := f(x + td),</code></pre><p>i.e.,</p><pre><code class="language-none">ϕ&#39;(t) = ∇f(x + td)ᵀd.</code></pre><p>The gradient ∇f(x + td) is stored in <code>g</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/SolverTools.jl/blob/328d30ab39f277f4784c373b13a3c5c0c230bc7f/src/linesearch/line_model.jl#L63-L73">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.grad-Tuple{LineModel, AbstractFloat}" href="#NLPModels.grad-Tuple{LineModel, AbstractFloat}"><code>NLPModels.grad</code></a> — <span class="docstring-category">Method</span></header><section><div><p><code>grad(f, t)</code> evaluates the first derivative of the <code>LineModel</code></p><pre><code class="language-none">ϕ(t) := f(x + td),</code></pre><p>i.e.,</p><pre><code class="language-none">ϕ&#39;(t) = ∇f(x + td)ᵀd.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/SolverTools.jl/blob/328d30ab39f277f4784c373b13a3c5c0c230bc7f/src/linesearch/line_model.jl#L48-L56">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.hess-Tuple{LineModel, AbstractFloat}" href="#NLPModels.hess-Tuple{LineModel, AbstractFloat}"><code>NLPModels.hess</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Evaluate the second derivative of the <code>LineModel</code></p><pre><code class="language-none">ϕ(t) := f(x + td),</code></pre><p>i.e.,</p><pre><code class="language-none">ϕ&quot;(t) = dᵀ∇²f(x + td)d.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/SolverTools.jl/blob/328d30ab39f277f4784c373b13a3c5c0c230bc7f/src/linesearch/line_model.jl#L110-L118">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.obj-Tuple{LineModel, AbstractFloat}" href="#NLPModels.obj-Tuple{LineModel, AbstractFloat}"><code>NLPModels.obj</code></a> — <span class="docstring-category">Method</span></header><section><div><p><code>obj(f, t)</code> evaluates the objective of the <code>LineModel</code></p><pre><code class="language-none">ϕ(t) := f(x + td).</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/SolverTools.jl/blob/328d30ab39f277f4784c373b13a3c5c0c230bc7f/src/linesearch/line_model.jl#L38-L42">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.objgrad!-Tuple{LineModel, AbstractFloat, AbstractVector}" href="#NLPModels.objgrad!-Tuple{LineModel, AbstractFloat, AbstractVector}"><code>NLPModels.objgrad!</code></a> — <span class="docstring-category">Method</span></header><section><div><p><code>objgrad!(f, t, g)</code> evaluates the objective and first derivative of the <code>LineModel</code></p><pre><code class="language-none">ϕ(t) := f(x + td),</code></pre><p>and</p><pre><code class="language-none">ϕ&#39;(t) = ∇f(x + td)ᵀd.</code></pre><p>The gradient ∇f(x + td) is stored in <code>g</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/SolverTools.jl/blob/328d30ab39f277f4784c373b13a3c5c0c230bc7f/src/linesearch/line_model.jl#L80-L90">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.objgrad-Tuple{LineModel, AbstractFloat}" href="#NLPModels.objgrad-Tuple{LineModel, AbstractFloat}"><code>NLPModels.objgrad</code></a> — <span class="docstring-category">Method</span></header><section><div><p><code>objgrad(f, t)</code> evaluates the objective and first derivative of the <code>LineModel</code></p><pre><code class="language-none">ϕ(t) := f(x + td),</code></pre><p>and</p><pre><code class="language-none">ϕ&#39;(t) = ∇f(x + td)ᵀd.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/SolverTools.jl/blob/328d30ab39f277f4784c373b13a3c5c0c230bc7f/src/linesearch/line_model.jl#L98-L106">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverTools.acceptable-Tuple{SolverTools.AbstractTrustRegion}" href="#SolverTools.acceptable-Tuple{SolverTools.AbstractTrustRegion}"><code>SolverTools.acceptable</code></a> — <span class="docstring-category">Method</span></header><section><div><p><code>acceptable(tr)</code></p><p>Return <code>true</code> if a step is acceptable, i.e. large or equal to <code>tr.acceptance_threshold</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/SolverTools.jl/blob/328d30ab39f277f4784c373b13a3c5c0c230bc7f/src/trust-region/trust-region.jl#L149-L153">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverTools.active!-Union{Tuple{T}, Tuple{BitVector, AbstractVector{T}, AbstractVector{T}, AbstractVector{T}}} where T&lt;:Real" href="#SolverTools.active!-Union{Tuple{T}, Tuple{BitVector, AbstractVector{T}, AbstractVector{T}, AbstractVector{T}}} where T&lt;:Real"><code>SolverTools.active!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">active!(indices, x, ℓ, u; rtol = 1e-8, atol = 1e-8)</code></pre><p>Update a <code>BitVector</code> of the active bounds at x, using tolerance <code>min(rtol * (uᵢ-ℓᵢ), atol)</code>. If ℓᵢ or uᵢ is not finite, only <code>atol</code> is used.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/SolverTools.jl/blob/328d30ab39f277f4784c373b13a3c5c0c230bc7f/src/auxiliary/bounds.jl#L25-L30">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverTools.active-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}, AbstractVector{T}}} where T&lt;:Real" href="#SolverTools.active-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}, AbstractVector{T}}} where T&lt;:Real"><code>SolverTools.active</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">active(x, ℓ, u; rtol = 1e-8, atol = 1e-8)</code></pre><p>Computes the active bounds at x, using tolerance <code>min(rtol * (uᵢ-ℓᵢ), atol)</code>. If ℓᵢ or uᵢ is not finite, only <code>atol</code> is used.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/SolverTools.jl/blob/328d30ab39f277f4784c373b13a3c5c0c230bc7f/src/auxiliary/bounds.jl#L6-L11">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverTools.aredpred!-Union{Tuple{V}, Tuple{T}, Tuple{SolverTools.AbstractTrustRegion{T, V}, NLPModels.AbstractNLPModel{T, V}, T, T, T, V, V, T}} where {T, V}" href="#SolverTools.aredpred!-Union{Tuple{V}, Tuple{T}, Tuple{SolverTools.AbstractTrustRegion{T, V}, NLPModels.AbstractNLPModel{T, V}, T, T, T, V, V, T}} where {T, V}"><code>SolverTools.aredpred!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">ared, pred = aredpred(tr, nlp, f, f_trial, Δm, x_trial, step, slope)
ared, pred = aredpred(tr, nls, Fx, f, f_trial, Δm, x_trial, step, slope)</code></pre><p>Compute the actual and predicted reductions <code>∆f</code> and <code>Δm</code>, where <code>ared = Δf = f_trial - f</code> is the actual reduction is an objective/merit/penalty function, <code>pred = Δm = m_trial - m</code> is the reduction predicted by the model <code>m</code> of <code>f</code>. We assume that <code>m</code> is being minimized, and therefore that <code>Δm &lt; 0</code>.</p><p>If <code>tr.good_grad</code> is <code>true</code>, then the gradient of <code>nlp</code> at <code>x_trial</code> is stored in <code>tr.gt</code>. For <code>AbstractNLSModel</code>, the argument <code>Fx</code> stores the residual if the gradient is updated.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/SolverTools.jl/blob/328d30ab39f277f4784c373b13a3c5c0c230bc7f/src/trust-region/trust-region.jl#L93-L104">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverTools.aredpred_common-Union{Tuple{V}, Tuple{T}, Tuple{NLPModels.AbstractNLPModel{T, V}, T, T, T, V, V, V, T}} where {T, V}" href="#SolverTools.aredpred_common-Union{Tuple{V}, Tuple{T}, Tuple{NLPModels.AbstractNLPModel{T, V}, T, T, T, V, V, V, T}} where {T, V}"><code>SolverTools.aredpred_common</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">ared, pred, good_grad = aredpred_common(nlp, f, f_trial, Δm, x_trial, step, g_trial, slope)
ared, pred, good_grad = aredpred_common(nlp, Fx, f, f_trial, Δm, x_trial, step, g_trial, slope)</code></pre><p>Compute the actual and predicted reductions <code>∆f</code> and <code>Δm</code>, where <code>ared = Δf = f_trial - f</code> is the actual reduction is an objective/merit/penalty function, <code>pred = Δm = m_trial - m</code> is the reduction predicted by the model <code>m</code> of <code>f</code>. We assume that <code>m</code> is being minimized, and therefore that <code>Δm &lt; 0</code>.</p><p><code>good_grad</code> is <code>true</code> if the gradient of <code>nlp</code> at <code>x_trial</code> has been updated and stored in <code>g_trial</code>. For <code>AbstractNLSModel</code>, the argument <code>Fx</code> stores the residual if the gradient is updated.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/SolverTools.jl/blob/328d30ab39f277f4784c373b13a3c5c0c230bc7f/src/trust-region/trust-region.jl#L26-L38">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverTools.armijo_condition-Union{Tuple{T}, NTuple{5, T}} where T" href="#SolverTools.armijo_condition-Union{Tuple{T}, NTuple{5, T}} where T"><code>SolverTools.armijo_condition</code></a> — <span class="docstring-category">Method</span></header><section><div><p>armijo_condition(h₀::T, ht::T, τ₀::T, t::T, slope::T)</p><p>Returns true if Armijo condition is satisfied for <code>τ₀</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/SolverTools.jl/blob/328d30ab39f277f4784c373b13a3c5c0c230bc7f/src/linesearch/armijo_goldstein.jl#L136-L140">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverTools.armijo_goldstein-Union{Tuple{T}, Tuple{LineModel, T, T}} where T&lt;:AbstractFloat" href="#SolverTools.armijo_goldstein-Union{Tuple{T}, Tuple{LineModel, T, T}} where T&lt;:AbstractFloat"><code>SolverTools.armijo_goldstein</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">t, ht, nbk, nbG = armijo_goldstein(h, h₀, slope)</code></pre><p>Perform a line search from <code>x</code> along the direction <code>d</code> as defined by the <code>LineModel</code> <code>h(t) = f(x + t d)</code>, where <code>h₀ = h(0) = f(x)</code>, and <code>slope = h&#39;(0) = ∇f(x)ᵀd</code>. The steplength is chosen to satisfy the Armijo-Goldstein conditions. The Armijo condition is</p><p class="math-container">\[h(t) ≤ h₀ + τ₀ t h&#39;(0)\]</p><p>and the Goldstein condition is</p><p class="math-container">\[h(t) ≥ h₀ + τ₁ t h&#39;(0).\]</p><p>with <code>0 &lt; τ₀ &lt; τ₁ &lt; 1</code>.</p><p><strong>Arguments</strong></p><ul><li><code>h::LineModel{T, S, M}</code>: 1-D model along the search direction <code>d</code>, <span>$h(t) = f(x + t d)$</span></li><li><code>h₀::T</code>: value of <code>h</code> at <code>t = 0</code></li><li><code>slope</code>: dot product of the gradient and the search direction, <span>$∇f(x)ᵀd$</span></li></ul><p><strong>Keyword arguments</strong></p><ul><li><code>t::T = one(T)</code>: initial steplength (default: <code>1</code>);</li><li><code>τ₀::T = T(eps(T)^(1/4))</code>: slope factor in the Armijo condition. It should satisfy <code>0 &lt; τ₀ &lt; τ₁ &lt; 1</code>;</li><li><code>τ₁::T = min(T(1)-eps(T), T(0.9999))</code>: slope factor in the Goldstein condition. It should satisfy <code>0 &lt; τ₀ &lt; τ₁ &lt; 1</code>;</li><li><code>γ₀::T = T(1 / 2)</code>: backtracking step length mutliplicative factor (0 &lt; γ₀ &lt;1)</li><li><code>γ₁::T = T(2)</code>: look-ahead step length mutliplicative factor (γ₁ &gt; 1)</li><li><code>bk_max</code>: maximum number of backtracks (default: <code>10</code>);</li><li><code>bG_max</code>: maximum number of increases (default: <code>10</code>);</li><li><code>verbose</code>: whether to print information (default: <code>false</code>).</li></ul><p><strong>Outputs</strong></p><ul><li><code>t::T</code>: the step length;</li><li><code>ht::T</code>: the model value at <code>t</code>, i.e., <code>f(x + t * d)</code>;</li><li><code>nbk::Int</code>: the number of times the steplength was decreased to satisfy the Armijo condition, i.e., the number of backtracks;</li><li><code>nbG::Int</code>: the number of times the steplength was increased to satisfy the Goldstein condition.</li></ul><p><strong>References</strong></p><p>This implementation follows the description given in</p><pre><code class="language-none">C. Cartis, P. R. Sampaio, Ph. L. Toint,
Worst-case evaluation complexity of non-monotone gradient-related algorithms for unconstrained optimization.
Optimization 64(5), 1349–1361 (2015).
DOI: 10.1080/02331934.2013.869809</code></pre><p>The method initializes an interval <code>[t_low,t_up]</code> guaranteed to contain a point satifying both Armijo and Goldstein conditions, and then uses a bisection algorithm to find such a point.   The method is implemented with M=0 (see reference), i.e., Armijo and Goldstein conditions are satisfied only for the current value of the objective <code>h₀</code>. </p><p><strong>Examples</strong></p><pre><code class="language-julia">using SolverTools, ADNLPModels
nlp = ADNLPModel(x -&gt; x[1]^2 + 4 * x[2]^2, ones(2))
lm = LineModel(nlp, nlp.meta.x0, -ones(2))

t, ft, nbk, nbG = armijo_goldstein(lm, obj(lm, 0.0), grad(lm, 0.0))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/SolverTools.jl/blob/328d30ab39f277f4784c373b13a3c5c0c230bc7f/src/linesearch/armijo_goldstein.jl#L3-L69">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverTools.armijo_wolfe-Union{Tuple{T}, Tuple{LineModel, T, T, Vector{T}}} where T&lt;:AbstractFloat" href="#SolverTools.armijo_wolfe-Union{Tuple{T}, Tuple{LineModel, T, T, Vector{T}}} where T&lt;:AbstractFloat"><code>SolverTools.armijo_wolfe</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">t, good_grad, ht, nbk, nbW = armijo_wolfe(h, h₀, slope, g)</code></pre><p>Performs a line search from <code>x</code> along the direction <code>d</code> as defined by the <code>LineModel</code> <span>$h(t) = f(x + t d)$</span>, where <code>h₀ = h(0) = f(x)</code>, <code>slope = h&#39;(0) = ∇f(x)ᵀd</code> and <code>g</code> is a vector that will be overwritten with the gradient at various points. On exit, if <code>good_grad=true</code>, <code>g</code> contains the gradient at the final step length. The steplength is chosen trying to satisfy the Armijo and Wolfe conditions. The Armijo condition is</p><p class="math-container">\[h(t) ≤ h₀ + τ₀ t h&#39;(0)\]</p><p>and the Wolfe condition is</p><p class="math-container">\[h&#39;(t) ≤ τ₁ h&#39;(0).\]</p><p>Initially the step is increased trying to satisfy the Wolfe condition. Afterwards, only backtracking is performed in order to try to satisfy the Armijo condition. The final steplength may only satisfy Armijo&#39;s condition.</p><p>The output is the following:</p><ul><li>t: the step length;</li><li>good_grad: whether <code>g</code> is the gradient at <code>x + t * d</code>;</li><li>ht: the model value at <code>t</code>, i.e., <code>f(x + t * d)</code>;</li><li>nbk: the number of times the steplength was decreased to satisfy the Armijo condition, i.e., number of backtracks;</li><li>nbW: the number of times the steplength was increased to satisfy the Wolfe condition.</li></ul><p>The following keyword arguments can be provided:</p><ul><li><code>t</code>: starting steplength (default <code>1</code>);</li><li><code>τ₀</code>: slope factor in the Armijo condition (default <code>max(1e-4, √ϵₘ)</code>);</li><li><code>τ₁</code>: slope factor in the Wolfe condition. It should satisfy <code>τ₁ &gt; τ₀</code> (default <code>0.9999</code>);</li><li><code>bk_max</code>: maximum number of backtracks (default <code>10</code>);</li><li><code>bW_max</code>: maximum number of increases (default <code>5</code>);</li><li><code>verbose</code>: whether to print information (default <code>false</code>).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/SolverTools.jl/blob/328d30ab39f277f4784c373b13a3c5c0c230bc7f/src/linesearch/armijo_wolfe.jl#L3-L37">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverTools.breakpoints-Union{Tuple{T}, NTuple{4, AbstractVector{T}}} where T&lt;:Real" href="#SolverTools.breakpoints-Union{Tuple{T}, NTuple{4, AbstractVector{T}}} where T&lt;:Real"><code>SolverTools.breakpoints</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">nbrk, brkmin, brkmax = breakpoints(x, d, ℓ, u)</code></pre><p>Find the smallest and largest values of <code>α</code> such that <code>x + αd</code> lies on the boundary. <code>x</code> is assumed to be feasible. <code>nbrk</code> is the number of breakpoints from <code>x</code> in the direction <code>d</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/SolverTools.jl/blob/328d30ab39f277f4784c373b13a3c5c0c230bc7f/src/auxiliary/bounds.jl#L55-L61">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverTools.compute_As_slope_qs!-Union{Tuple{T}, Tuple{AbstractVector{T}, Union{LinearOperators.AbstractLinearOperator, AbstractMatrix}, AbstractVector{T}, AbstractVector{T}}} where T&lt;:Real" href="#SolverTools.compute_As_slope_qs!-Union{Tuple{T}, Tuple{AbstractVector{T}, Union{LinearOperators.AbstractLinearOperator, AbstractMatrix}, AbstractVector{T}, AbstractVector{T}}} where T&lt;:Real"><code>SolverTools.compute_As_slope_qs!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">slope, qs = compute_As_slope_qs!(As, A, s, Fx)</code></pre><p>Compute <code>slope = dot(As, Fx)</code> and <code>qs = dot(As, As) / 2 + slope</code>. Use <code>As</code> to store <code>A * s</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/SolverTools.jl/blob/328d30ab39f277f4784c373b13a3c5c0c230bc7f/src/auxiliary/bounds.jl#L114-L118">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverTools.compute_Hs_slope_qs!-Union{Tuple{T}, Tuple{AbstractVector{T}, Union{LinearOperators.AbstractLinearOperator, AbstractMatrix}, AbstractVector{T}, AbstractVector{T}}} where T&lt;:Real" href="#SolverTools.compute_Hs_slope_qs!-Union{Tuple{T}, Tuple{AbstractVector{T}, Union{LinearOperators.AbstractLinearOperator, AbstractMatrix}, AbstractVector{T}, AbstractVector{T}}} where T&lt;:Real"><code>SolverTools.compute_Hs_slope_qs!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">slope, qs = compute_Hs_slope_qs!(Hs, H, s, g)</code></pre><p>Computes</p><pre><code class="language-none">Hs = H * s
slope = dot(g,s)
qs = ¹/₂sᵀHs + slope</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/SolverTools.jl/blob/328d30ab39f277f4784c373b13a3c5c0c230bc7f/src/auxiliary/bounds.jl#L93-L101">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverTools.compute_r-Union{Tuple{T}, Tuple{Any, T, Vararg{Any, 7}}} where T" href="#SolverTools.compute_r-Union{Tuple{T}, Tuple{Any, T, Vararg{Any, 7}}} where T"><code>SolverTools.compute_r</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">compute_r(nlp, f, Δf, Δq, slope, d, xnext, gnext, robust)</code></pre><p>Compute the actual vs predicted reduction ratio <code>∆f/Δq</code>.</p><p>Arguments:</p><ul><li><code>nlp</code>: Current model we are trying to solve</li><li><code>f</code>: current objective value</li><li><code>Δf</code>: <code>= f - f_trial</code> is the actual reduction is an objective/merit/penalty function,</li><li><code>Δq</code>: <code>q - q_trial</code> is the reduction predicted by the model q of f.</li><li><code>slope</code>: current slope</li><li><code>d</code>: potential next direction</li><li><code>xnext</code>: potential next iterate</li><li><code>gnext</code>: current gradient value, if <code>good_grad</code> is true, then this value has been udpated.</li><li><code>robust</code>: if <code>true</code>, try to trap potential cancellation errors</li></ul><p>Output:</p><ul><li><code>r</code>: reduction ratio <code>∆f/Δq</code></li><li><code>good_grad</code>: <code>true</code> if <code>gnext</code> has been recomputed</li><li><code>gnext</code>: gradient.</li></ul><p>We assume that <code>q</code><code>is being minimized, and therefore that</code>Δq &gt; 0`.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/SolverTools.jl/blob/328d30ab39f277f4784c373b13a3c5c0c230bc7f/src/trust-region/ar-trust-region.jl#L65-L87">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverTools.goldstein_condition-Union{Tuple{T}, NTuple{5, T}} where T" href="#SolverTools.goldstein_condition-Union{Tuple{T}, NTuple{5, T}} where T"><code>SolverTools.goldstein_condition</code></a> — <span class="docstring-category">Method</span></header><section><div><p>goldstein_condition(h₀::T, ht::T, τ₁::T, t::T, slope::T)</p><p>Returns true if Goldstein condition is satisfied for <code>τ₁</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/SolverTools.jl/blob/328d30ab39f277f4784c373b13a3c5c0c230bc7f/src/linesearch/armijo_goldstein.jl#L145-L149">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverTools.hess!-Tuple{LineModel, AbstractFloat, AbstractVector}" href="#SolverTools.hess!-Tuple{LineModel, AbstractFloat, AbstractVector}"><code>SolverTools.hess!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Evaluate the second derivative of the <code>LineModel</code></p><pre><code class="language-none">ϕ(t) := f(x + td),</code></pre><p>i.e.,</p><pre><code class="language-none">ϕ&quot;(t) = dᵀ∇²f(x + td)d.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/SolverTools.jl/blob/328d30ab39f277f4784c373b13a3c5c0c230bc7f/src/linesearch/line_model.jl#L124-L132">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverTools.project!-Union{Tuple{T}, NTuple{4, AbstractVector{T}}} where T&lt;:Real" href="#SolverTools.project!-Union{Tuple{T}, NTuple{4, AbstractVector{T}}} where T&lt;:Real"><code>SolverTools.project!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">project!(y, x, ℓ, u)</code></pre><p>Projects <code>x</code> into bounds <code>ℓ</code> and <code>u</code>, in the sense of <code>yᵢ = max(ℓᵢ, min(xᵢ, uᵢ))</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/SolverTools.jl/blob/328d30ab39f277f4784c373b13a3c5c0c230bc7f/src/auxiliary/bounds.jl#L131-L136">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverTools.project_step!-Union{Tuple{T}, NTuple{5, AbstractVector{T}}, Tuple{AbstractVector{T}, AbstractVector{T}, AbstractVector{T}, AbstractVector{T}, AbstractVector{T}, Real}} where T&lt;:Real" href="#SolverTools.project_step!-Union{Tuple{T}, NTuple{5, AbstractVector{T}}, Tuple{AbstractVector{T}, AbstractVector{T}, AbstractVector{T}, AbstractVector{T}, AbstractVector{T}, Real}} where T&lt;:Real"><code>SolverTools.project_step!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">project_step!(y, x, d, ℓ, u, α = 1.0)</code></pre><p>Computes the projected direction <code>y = P(x + α * d) - x</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/SolverTools.jl/blob/328d30ab39f277f4784c373b13a3c5c0c230bc7f/src/auxiliary/bounds.jl#L146-L150">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverTools.redirect!-Tuple{LineModel, AbstractVector, AbstractVector}" href="#SolverTools.redirect!-Tuple{LineModel, AbstractVector, AbstractVector}"><code>SolverTools.redirect!</code></a> — <span class="docstring-category">Method</span></header><section><div><p><code>redirect!(ϕ, x, d)</code></p><p>Change the values of x and d of the LineModel ϕ, but retains the counters.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/SolverTools.jl/blob/328d30ab39f277f4784c373b13a3c5c0c230bc7f/src/linesearch/line_model.jl#L29-L33">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SolverTools.update!" href="#SolverTools.update!"><code>SolverTools.update!</code></a> — <span class="docstring-category">Function</span></header><section><div><p><code>update!(tr, step_norm)</code></p><p>Update the trust-region radius based on the ratio <code>tr.ratio</code> of actual vs. predicted reduction and the step norm.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/SolverTools.jl/blob/328d30ab39f277f4784c373b13a3c5c0c230bc7f/src/trust-region/trust-region.jl#L166-L171">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Friday 3 May 2024 11:11">Friday 3 May 2024</span>. Using Julia version 1.10.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
